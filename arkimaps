#!/usr/bin/python3
from __future__ import annotations
from typing import ContextManager
import argparse
import logging
import tarfile
import tempfile
import subprocess
import contextlib
import multiprocessing.pool
import json
import io
import os
import sys
import time
from arkimapslib.recipes import Recipes, Order

log = logging.getLogger("arkimaps")


class Fail(Exception):
    pass


class LogCollector(logging.Handler):
    def __init__(self, *args, **kw):
        super().__init__(*args, **kw)
        self.entries = []

    def emit(self, record: logging.LogRecord):
        entry = {
            'ts': time.clock_gettime_ns(time.CLOCK_REALTIME),
            'level': record.levelno,
            'msg': self.format(record),
            'name': record.name
        }
        self.entries.append(entry)


def prepare_order(order: Order) -> Order:
    order.prepare()
    return order


class Arkimaps:
    """
    Top-level command line implementation
    """
    def __init__(self, args):
        from arkimapslib.pantry import ArkimetPantry, GribPantry
        if args.filter == "arkimet":
            Pantry = ArkimetPantry
        elif args.filter == "eccodes":
            Pantry = GribPantry
        else:
            raise Fail(f"Unsupported value `{args.filter}` for --filter")
        self.args = args

        # Collect log entries that we can then add to the output data
        self.log_collector = LogCollector()
        self.log_collector.setLevel(logging.DEBUG)
        root_logger = logging.getLogger()
        root_logger.addHandler(self.log_collector)

        # Set up working directory
        self.tempdir = None
        if self.args.workdir is None:
            self.tempdir = tempfile.TemporaryDirectory()
            self.workdir = self.tempdir.name
            self.pantry = Pantry(self.workdir)
        else:
            self.workdir = self.args.workdir
            self.pantry = Pantry(self.workdir)

        # Load recipes
        self.recipes = Recipes()
        self.recipes.load(self.pantry.session, "recipes")

    @contextlib.contextmanager
    def magics_worker_pool(self) -> ContextManager[multiprocessing.pool.Pool]:
        def initializer():
            # Tell magics where it should take its default styles from
            os.environ["MAGICS_STYLE_PATH"] = self.args.styles
            # Tell magics not to print noisy banners
            os.environ["MAGPLUS_QUIET"] = "1"

        # Using maxtasksperchild to regularly restart the workers, to mitigate
        # possible Magics memory leaks
        with multiprocessing.pool.Pool(initializer=initializer, maxtasksperchild=16) as pool:
            yield pool

    def do_document_recipes(self):
        """
        Generate recipes documentation
        """
        self.recipes.document(self.args.recipes)

    def do_dispatch(self):
        """
        Acquire input data
        """
        self.pantry.fill(self.recipes)

    def do_preview(self, name: str, step: int):
        """
        Generate the given product only, and preview it with xdg-open
        """
        # Make an order
        order = self.pantry.order(self.recipes, name, step)

        # Prepare it
        order.prepare()
        log.info("Rendered %s to %s", order.recipe, order.basename)

        # Display it
        subprocess.run(["xdg-open", order.output], check=True)
        input("Press enter when done:")
        os.unlink(order.output)

    def open_output(self):
        if self.args.output:
            return tarfile.open(self.args.output, mode="w|")
        else:
            return tarfile.open(mode="w|", fileobj=sys.stdout.buffer)

    def do_render(self):
        """
        Render all recipes for which inputs are available
        """
        with self.open_output() as tarout:
            # List of products that should be rendered
            orders = list(self.pantry.orders(self.recipes))

            with self.magics_worker_pool() as pool:
                for order in pool.imap_unordered(prepare_order, orders):
                    log.info("Rendered %s to %s", order.recipe, order.basename)

                    # Move the generated image to the output tar
                    tarout.add(order.output, os.path.join(order.recipe, order.basename + ".png"))
                    os.unlink(order.output)

            if self.log_collector.entries:
                with io.BytesIO(json.dumps(self.log_collector.entries, indent=1).encode()) as buf:
                    info = tarfile.TarInfo(name="log.json")
                    info.size = len(buf.getvalue())
                    tarout.addfile(tarinfo=info, fileobj=buf)

            # Let the Pantry store processing artifacts if it has any
            self.pantry.store_processing_artifacts(tarout)


def main():
    default_styles = os.path.abspath(os.path.join(os.path.dirname(sys.argv[0]), "styles"))
    if not os.path.isdir(default_styles):
        default_styles = "/usr/share/magics/styles/ecmwf"

    parser = argparse.ArgumentParser(description="Render model maps")
    parser.add_argument("--verbose", "-v", action="store_true",
                        help="verbose output")
    parser.add_argument("--debug", action="store_true",
                        help="debug output")
    parser.add_argument("--styles", metavar="dir", action="store", default=default_styles,
                        help="styles directory. Default: styles (if existing) or /usr/share/magics/styles/ecmwf")
    parser.add_argument("--workdir", metavar="dir", action="store",
                        help="working directory. Default: a temporary one")
    parser.add_argument("--output", "-o", metavar="file.tar", action="store",
                        help="write rendered output to the given file. Default: write to stdout")
    parser.add_argument("--recipes", metavar="dir", action="store", default="recipes",
                        help="directory with the YAML recipes")
    parser.add_argument("--render", action="store_true",
                        help="do not read data: render from an existing working directory")
    parser.add_argument("--dispatch", action="store_true",
                        help="do not render: dispatch into a working directory")
    parser.add_argument("--document-recipes", action="store_true",
                        help="generate recipes documentation")
    parser.add_argument("--filter", metavar="{arkimet|eccodes}", default="arkimet",
                        help="backend to use to organise data into recipe inputs. Default: %(default)s")
    parser.add_argument("--preview", metavar="name+nnn",
                        help="generate the given product only, and display it with xdg-open")
    args = parser.parse_args()

    # Setup logging
    FORMAT = "%(asctime)-15s %(levelname)s %(message)s"
    log_handler = logging.StreamHandler(sys.stderr)
    log_handler.setFormatter(logging.Formatter(FORMAT))
    if args.debug:
        log_handler.setLevel(logging.DEBUG)
    elif args.verbose:
        log_handler.setLevel(logging.INFO)
    else:
        log_handler.setLevel(logging.WARN)
    root_logger = logging.getLogger()
    root_logger.addHandler(log_handler)
    root_logger.setLevel(logging.DEBUG)

    arkimaps = Arkimaps(args)

    if args.render:
        if not args.workdir:
            raise Fail("Please use --workdir when you use --render")
        arkimaps.do_render()
    elif args.dispatch:
        if not args.workdir:
            raise Fail("Please use --workdir when you use --render")
        arkimaps.do_dispatch()
    elif args.document_recipes:
        arkimaps.do_document_recipes()
    elif args.preview:
        name, step = args.preview.split("+")
        arkimaps.do_preview(name, int(step, 10))
    else:
        arkimaps.do_dispatch()
        arkimaps.do_render()


if __name__ == "__main__":
    try:
        main()
    except Fail as e:
        print(e, file=sys.stderr)
        sys.exit(1)
